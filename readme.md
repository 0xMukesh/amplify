# amplify

A character-level language model which generates more content based on the input data, built using RNN architecture

### todo

- [x] implement basic bigram model implementation
- [x] implement multi-layer perceptron, ref: ["A Neural Probabilistic Language Model"](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- [x] add batchnorm, ref: ["Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"](https://arxiv.org/pdf/1502.03167)
- [x] read about problems of batchnorm, ref: ["Rethinking “Batch” in BatchNorm"](https://arxiv.org/pdf/2105.07576)
- [ ] implement RNN archietecture
- [ ] read wavenet's paper, ref: ["WaveNet: A generative model for raw audio"](https://arxiv.org/pdf/1609.03499)
